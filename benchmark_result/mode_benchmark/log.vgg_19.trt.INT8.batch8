
WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
If you depend on functionality not listed there, please file an issue.

2019-03-05 23:17:57.503410: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2019-03-05 23:17:57.507836: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-03-05 23:18:02.564665: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1009] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-03-05 23:18:02.565497: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-03-05 23:18:02.565828: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1467] Found device 0 with properties: 
name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:00:04.0
totalMemory: 15.75GiB freeMemory: 15.34GiB
2019-03-05 23:18:02.565856: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1546] Adding visible gpu devices: 0
2019-03-05 23:18:02.565893: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-03-05 23:18:02.566949: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1015] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-05 23:18:02.566973: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1021]      0 
2019-03-05 23:18:02.566982: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1034] 0:   N 
2019-03-05 23:18:02.567212: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1149] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14926 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0)
('Using checkpoint:', './data/vgg_19/vgg_19.ckpt')
WARNING: Logging before flag parsing goes to stderr.
W0305 23:18:03.040083 140057710683904 deprecation.py:323] From /home/laigd/mytfpy2/virtualenv_py2/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
W0305 23:18:06.128995 140057710683904 deprecation.py:323] From image_classification.py:418: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.convert_variables_to_constants`
W0305 23:18:06.129267 140057710683904 deprecation.py:323] From /home/laigd/mytfpy2/virtualenv_py2/local/lib/python2.7/site-packages/tensorflow/python/framework/graph_util_impl.py:247: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.extract_sub_graph`
2019-03-05 23:18:13.450088: I tensorflow/core/grappler/devices.cc:50] Number of eligible GPUs (core count >= 8): 1
2019-03-05 23:18:13.450311: I tensorflow/core/grappler/clusters/single_machine.cc:359] Starting new session
2019-03-05 23:18:13.451432: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1546] Adding visible gpu devices: 0
2019-03-05 23:18:13.648323: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1015] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-05 23:18:13.648385: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1021]      0 
2019-03-05 23:18:13.648397: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1034] 0:   N 
2019-03-05 23:18:13.648669: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1149] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14926 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0)
2019-03-05 23:18:33.703833: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:456] There are 5 ops of 4 different types in the graph that are not converted to TensorRT: ArgMax, Identity, Placeholder, NoOp, (For more information see https://docs.nvidia.com/deeplearning/dgx/integrate-tf-trt/index.html#support-ops).
2019-03-05 23:18:33.705207: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:839] Number of TensorRT candidate segments: 1
2019-03-05 23:18:35.579848: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-03-05 23:18:40.654714: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-03-05 23:18:42.112310: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-03-05 23:19:07.174416: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:939] TensorRT node TRTEngineOp_0 added for segment 0 consisting of 106 nodes succeeded.
2019-03-05 23:19:09.132265: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:666] Optimization results for grappler item: tf_graph
2019-03-05 23:19:09.132347: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:668]   constant folding: Graph size after: 106 nodes (-38), 105 edges (-38), time = 8450.00684ms.
2019-03-05 23:19:09.132357: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:668]   layout: Graph size after: 110 nodes (4), 109 edges (4), time = 2066.35ms.
2019-03-05 23:19:09.132367: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:668]   constant folding: Graph size after: 110 nodes (0), 109 edges (0), time = 3084.73804ms.
2019-03-05 23:19:09.132376: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:668]   TensorRTOptimizer: Graph size after: 5 nodes (-105), 4 edges (-105), time = 38035.6562ms.
2019-03-05 23:19:34.636851: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1546] Adding visible gpu devices: 0
2019-03-05 23:19:34.636948: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1015] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-05 23:19:34.636960: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1021]      0 
2019-03-05 23:19:34.636970: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1034] 0:   N 
2019-03-05 23:19:34.637156: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1149] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14926 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0)
2019-03-05 23:20:04.346718: I tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:698] Starting calibration thread on device 0, Calibration Resource @ 0x7f5f94007260
2019-03-05 23:21:27.146599: I tensorflow/compiler/tf2tensorrt/utils/trt_resources.cc:25] Destroying Calibration Resource 
 Calibrator = 0x7f5f94007320
 Builder    = 0
 Engine     = 0x7f5cfc078990
 Logger     = 0x7f5f940072e0
 Allocator  = 0x7f5f940071e0
 Thread     = 0x7f5f94007420

batch_size: 8
cache: False
calib_data_dir: /home/laigd/tftrtrepo/data
data_dir: /home/laigd/tftrtrepo/data
default_models_dir: ./data
display_every: 100
max_workspace_size: 4294967296
minimum_segment_size: 2
mode: benchmark
model: vgg_19
model_dir: None
num_calib_inputs: 8
num_iterations: 200
num_warmup_iterations: 50
precision: INT8
target_duration: None
use_synthetic: True
use_trt: True
use_trt_dynamic_op: False
url: http://download.tensorflow.org/models/vgg_19_2016_08_28.tar.gz
num_nodes(native_tf): 144
num_nodes(tftrt_total): 5
num_nodes(trt_only): 1
graph_size(MB)(native_tf): 548.1
graph_size(MB)(trt): 1096.1
time(s)(trt_conversion): 67.1
running inference...
W0305 23:21:27.515022 140057710683904 estimator.py:974] Input graph does not use tf.data.Dataset or contain a QueueRunner. That means predict yields forever. This is probably a mistake.
2019-03-05 23:21:43.220268: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1546] Adding visible gpu devices: 0
2019-03-05 23:21:43.220372: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1015] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-05 23:21:43.220383: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1021]      0 
2019-03-05 23:21:43.220393: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1034] 0:   N 
2019-03-05 23:21:43.220586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1149] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14926 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0)
('    running for target duration from %d', 1551828119.706348)
2019-03-05 23:22:26.622447: I tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:613] Building a new TensorRT engine for TRTEngineOp_0 input shapes: [[8,224,224,3]]
    step 100/13, iter_time(ms)=6.7980, images/sec=1176
    step 200/13, iter_time(ms)=6.7289, images/sec=1188
results of vgg_19:
    images/sec: 1181
    99th_percentile(ms): 6.8
    total_time(s): 1.0
    latency_mean(ms): 6.8
